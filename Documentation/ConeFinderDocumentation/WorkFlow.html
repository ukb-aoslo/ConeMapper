<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,IE=9,chrome=1"><meta name="generator" content="MATLAB 2022a"><title>WorkFlow</title><style type="text/css">.rtcContent { padding: 30px; } .S0 { margin: 3px 10px 5px 4px; padding: 0px; line-height: 28.8px; min-height: 0px; white-space: pre-wrap; color: rgb(192, 76, 11); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 24px; font-weight: 400; text-align: left;  }
.S1 { margin: 2px 10px 9px 4px; padding: 0px; line-height: 21px; min-height: 0px; white-space: pre-wrap; color: rgb(33, 33, 33); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 14px; font-weight: 400; text-align: left;  }
.S2 { margin: 10px 0px 20px; padding-left: 0px; font-family: Helvetica, Arial, sans-serif; font-size: 14px;  }
.S3 { margin-left: 56px; line-height: 21px; min-height: 0px; text-align: left; white-space: pre-wrap;  }
.S4 { margin: 10px 10px 5px 4px; padding: 0px; line-height: 18px; min-height: 0px; white-space: pre-wrap; color: rgb(33, 33, 33); font-family: Helvetica, Arial, sans-serif; font-style: normal; font-size: 15px; font-weight: 700; text-align: left;  }</style></head><body><div class = rtcContent><h1  class = 'S0'><span>WorkFlow</span></h1><div  class = 'S1'><span>General work flow with the Cone Finder app is the next:</span></div><ol  class = 'S2'><li  class = 'S3'><span>You need the image file of the fovea (confocal).</span></li><li  class = 'S3'><span>First of all, you put the image through the recognition by Neural network (or other options): File -&gt; New recognition.</span></li><li  class = 'S3'><span>After recognition you can manually tune the result.</span></li><li  class = 'S3'><span>Filtering options, Cone representation options and Voronoi diagram available right away and updates on the fly. Also, you can calculate Yellots ring based density right away, because it is image based approach and does not use cone annotations.</span></li><li  class = 'S3'><span>After you finished the recognition of the cones you can calculate density metrics based on cone annotations.</span></li><li  class = 'S3'><span>Start your analysis.</span></li></ol><h4  class = 'S4'><span>Important!</span></h4><div  class = 'S1'><span>If you changed cone annotations, you should manually recalculate the density metrics based on cone annotations (EuclidianNcones, NNDmean).</span></div>
<br>
<!-- 
##### SOURCE BEGIN #####
%% WorkFlow
% General work flow with the Cone Finder app is the next:
%% 
% # You need the image file of the fovea (confocal).
% # First of all, you put the image through the recognition by Neural network 
% (or other options): File -> New recognition.
% # After recognition you can manually tune the result.
% # Filtering options, Cone representation options and Voronoi diagram available 
% right away and updates on the fly. Also, you can calculate Yellots ring based 
% density right away, because it is image based approach and does not use cone 
% annotations.
% # After you finished the recognition of the cones you can calculate density 
% metrics based on cone annotations.
% # Start your analysis.
% Important!
% If you changed cone annotations, you should manually recalculate the density 
% metrics based on cone annotations (EuclidianNcones, NNDmean).
##### SOURCE END #####
-->
</div></body></html>